{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UFw0P967K7QD",
        "1mGorHTWLBPw"
      ],
      "authorship_tag": "ABX9TyPnPyFCA+9NKJCrHnfpzp2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmidGhadami95/Caregivers/blob/main/Caregivers_Narrative_Plus_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**"
      ],
      "metadata": {
        "id": "6lNPPqSzzQlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "metadata": {
        "id": "5vJxuvpfMlPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge PHQ_demographic to Narrative data"
      ],
      "metadata": {
        "id": "BecvMu5DxM7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "hhlBmik3ojgs",
        "outputId": "449e8490-d48b-4aad-c0bf-77685f36f2d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Participant ID  Age  Sex  Race  Ethnicity  Location  Employment  Education  \\\n",
              "0               1    0    0     0          0         0           0          0   \n",
              "1               2    0    0     0          0         1           0          0   \n",
              "2               3    0    0     0          0         0           1          0   \n",
              "3               4    0    0     0          0         0           0          0   \n",
              "4               5    0    0     0          0         1           1          0   \n",
              "\n",
              "   Income  Health Insurance  Relationship to Loved One  Years Caring  \\\n",
              "0       0                 0                          0             0   \n",
              "1       1                 0                          0             1   \n",
              "2       1                 1                          0            10   \n",
              "3       0                 0                          1            10   \n",
              "4       1                 0                          1            10   \n",
              "\n",
              "   Daily Caregiving Hours  PHQ_score  \\\n",
              "0                       0          0   \n",
              "1                       1          1   \n",
              "2                       1          0   \n",
              "3                       0          1   \n",
              "4                       0          1   \n",
              "\n",
              "                                                 ACD  \\\n",
              "0  yeah can i read questions first ok uh my name ...   \n",
              "1  ok ok so my name is jonathan im fergal years o...   \n",
              "2  alright my full name is brian brian hemsworth ...   \n",
              "3  yeah my name is montana franklin im years old ...   \n",
              "4  ok im victor daniel my name is victor daniel y...   \n",
              "\n",
              "                                                 ADJ  \\\n",
              "0  palma real few artificial helpful loved many a...   \n",
              "1  fergal old biological old close same primary s...   \n",
              "2  full old easy more much ill best problematic f...   \n",
              "3  old dead easy ready same same same clinical se...   \n",
              "4  old challenging past ok social religious posit...   \n",
              "\n",
              "                                                 UNI  \n",
              "0  yeah can i read questions first ok uh my name ...  \n",
              "1  ok ok so my name is jonathan i m fergal years ...  \n",
              "2  alright my full name is brian brian hemsworth ...  \n",
              "3  yeah my name is montana franklin i m years old...  \n",
              "4  ok i m victor daniel my name is victor daniel ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0bed1e8-f11b-4e85-a379-fe55e7141d13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Race</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Location</th>\n",
              "      <th>Employment</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "      <th>Health Insurance</th>\n",
              "      <th>Relationship to Loved One</th>\n",
              "      <th>Years Caring</th>\n",
              "      <th>Daily Caregiving Hours</th>\n",
              "      <th>PHQ_score</th>\n",
              "      <th>ACD</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>UNI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>yeah can i read questions first ok uh my name ...</td>\n",
              "      <td>palma real few artificial helpful loved many a...</td>\n",
              "      <td>yeah can i read questions first ok uh my name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ok ok so my name is jonathan im fergal years o...</td>\n",
              "      <td>fergal old biological old close same primary s...</td>\n",
              "      <td>ok ok so my name is jonathan i m fergal years ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>alright my full name is brian brian hemsworth ...</td>\n",
              "      <td>full old easy more much ill best problematic f...</td>\n",
              "      <td>alright my full name is brian brian hemsworth ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>yeah my name is montana franklin im years old ...</td>\n",
              "      <td>old dead easy ready same same same clinical se...</td>\n",
              "      <td>yeah my name is montana franklin i m years old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ok im victor daniel my name is victor daniel y...</td>\n",
              "      <td>old challenging past ok social religious posit...</td>\n",
              "      <td>ok i m victor daniel my name is victor daniel ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0bed1e8-f11b-4e85-a379-fe55e7141d13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0bed1e8-f11b-4e85-a379-fe55e7141d13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0bed1e8-f11b-4e85-a379-fe55e7141d13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e158782b-b3a3-4306-9a05-cf12ebbe151c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e158782b-b3a3-4306-9a05-cf12ebbe151c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e158782b-b3a3-4306-9a05-cf12ebbe151c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 65,\n  \"fields\": [\n    {\n      \"column\": \"Participant ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 1,\n        \"max\": 68,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          57,\n          64,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Race\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ethnicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Employment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Health Insurance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Relationship to Loved One\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Years Caring\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Daily Caregiving Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHQ_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ACD\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"im alexia bonnie years single im living with my parents i stay with my parents as who i does i do care given with i am i am only caregiver for her share how you have been feeling in past few weeks while taking care of your loved one with dementia tell us about any moment whether positive challenging that stand out to you it has been negative life for me thats reduced my parting my my my studies everything about me so it has been difficult life life for me going to parties im going to school too i have stopped schools i have been taking care of my mother i have stopped school there is no positive moment in financial aspects i dont have any money to take care of her again like whenever im cooking she will be screaming shouting yelling i will leave that to my meter again to take care of her no no positive moment ok describe ok giving assisting you about wellbeing past few weeks regarding your relationship with family friends comics to internet changes shifts relationships question too i have not i have not noticed any changes it has been way i have been given my life for past five years i invite only one of my friends has told by me for past four years five years i i told you other time but my family friends are no more they have they have gone they left me alone its only one of my friends that stay with me whenever i call her she used to take three to four days to come ok over past few weeks yes please my decision making has changed due to food i eat at home financial everything because of of my mothers sickness yes i do think about her i have to put her into consideration first number four question describe your selfcare practices in past few weeks to manage daily stresses of caregiving share your strategy strategies that have been particularly helpful in coping with steady stress of caregiving ok time i cook for her time i do i do take care of her time of caring time of management time of making her happy thats ok then thats what i can say for that number four question please i go on social media will i surf internet to rest i used to rest whenever i take care of us i whenever she is asleep i used to sleep too i used to take rest my make sure i wake up before i used to sleep very well before go out go to schools go to clubs i used to party very well but now i dont used to do that again i used to drive i i will put on car drive out wherever whenever wherever im going sorry i dont used to leave her at home go out i go with i go out with her ill put her inside car go out nobody to stay with her in past few weeks of earning factors such as professional commitment financial constraints for health challenges influence how you fees based on this these special therapists are attention caregiver used to allow her to allow person to come but now there is no financial support again from anybody im not financially buoyant now yes i cant hear you fair enough im im fair enough fair enough health my isnt my home my mothers health my health at least im copying little i get tired stress is too much for me i get tired every now then im because im taking care of my mother because im im caregiver to my mother ive not seen any support from anyone i work remotely just work for three hours remaining hours is for taking care of her no hes answer my mother im doing it because of my mother ill just make sure that i have given her her drugs her food then ill start working it has reduced my wages like like weeks ago now when i was working she she was awake what do i do ah i used to give her more than more than hours as key given do you sometimes feel concerned about what future holds for you in that room if so could you share more about it what kind of help support will bear for you economist question as caregiver do you sometimes feel concerned about future what future holds for you in that yes because i need partner i will still have ill im here i need to dedicate my time to her voting of attention to financial support i cant remember not really i cant remember anything now so i had to attend to her before going she can remember me i show her some old videos of ours some pictures lots more she she react amazingly she goes into her room when someone comes in as in she as she reacts amazingly sometimes not every time no no not him stressful\",\n          \"my name is john smith i am years old i am child to you know person with dementia is my father ok im only one who is major caregiver ok answering question one well for past few weeks yeah its about years to years hes why so weak so before going to my job i ensure hes fine i provide every basic things he needs you know he slowed his his emails his phone calls voicemails he has sure everything are kept in check sure hes using his medication they are all set before i go to my job at my job i always calling i calling at least twice to check on him to make sure hes doing fine make sure hes not having any reaction side effects to medication make sure hes resting one is supposed to make sure hes doing little exercise that has been prepared for him you know when im back also i take him we go for walk take stroll around we do little exercise sometimes we go to church together there sure he also eats well eat fruits eats necessary things those use medication those little exercise then also on days of his visit to hospital so its just like normal thing you do for your child i immediately im responsible for most of things ok someone says that ok well for past few weeks i would say pressure is much more lesser than before then i had you know when we first started it was lot for me to taking balancing being caregiver also having full time job its really really tough its really tough then being at entry level someone with little i have buses which im also under their command you know its really hard to have my wish in time like that so then also its its always very difficult coping with new development you know things your father can do before easily before you find it you say that hes having hard time doing them you always just have to be around ensuring that it does it right so its always very tough to take in its really hard to believe that this is happening so for for past few weeks ice after that im finding it little bit more easier because ive let it become part of me ive let it become something i do you know i would im willing to go extra mile to make sure theyre ok theyre fine because theyve also sacrificed lot for me so for past few weeks i have made it my habits you know something i do without being for something i do without seeing it thats hard job though theres lot of challenge definitely lot of challenge tell him something he forgets it easily has few reactions some things you did yesterday you can remember some things you know lot of things lot of challenges but ive learned to just calm down you know sometimes when its overwhelming i just take walk just listen to music just do something to calm me myself down because i cannot be transferring aggression to him i cannot show any sign of no anger any other things because it would really really affect his own wellbeing so i rather would rather take walk on his throat rather just turn my earbuds on listen to loud music just do something to just chill off before i can actually think on what next to do so i would say im really coping nicely im finding strategies to make it much more easier for me so thats how that is ok well relationship with friends family colleagues definitely there is shift i spend more time at home apart from my job apart from my job you know most times then i would love to socialize you know visit friends go to watch game go to at club go to lottery houses you know i spent my most of my free times there my weekends you know im socializing im hanging out im doing lot of stuff sports now i have to spend there with my parents my dad because he needs care everything is getting better though but he needs care so thats affected my relationship with my friends well it makes me my wife have much more time together since im spending more time at home with my father shes always around too so but with my friends thats really severed relationship we do lot of call video calls you know voice calls to kind of compensate for may not being able to show up there sometimes that some occasions will clash with days he has to go to hospital so its really done little to that my friends my colleagues you know my colleague maybe having birthday celebration at his home hes having occasion its classes with sometime by time i have to just be with my dad so most of them do actually understand they understand my situation they dont get annoyed so we go to watch some basketball sometimes makes him more happy makes him lively you know you see him celebrate him when he sees says he hook he goes cold some other things makes him more lively you know it adds makes health better some other things so thats pretty much how when i go out then relationship with my friends colleagues it has done little damage to it definitely i it has it is about where its stopping me from going out its making me spend more time at home spend more time with my dad just ensuring that things are going as it should but i dont see that as you know when you people say barrier you know its something very negative something terrible something you dont want to but it is what it is now im not seeing it as barrier im just saying that is that how can i describe it as alternative you know im learning new way of life instead of being that you know extroverts talk so much going out partying having so much fun spending money wasting money wasting time doing some other things i now taking all those energies transfer it into something useful apart from while im even caregiving i have some remote things i do i trade crypto i do some other things so i want to say its barrier anymore it has taught me how to actually invest in myself do things while im at home so that also helped me in way ok well in my decision making process i think no real change no real change no real change any decision i need to make you know in regards to him sometimes he actually is able to make few decisions sometimes you know explaining some things to him he doesnt understand we write it down let him greet we play it let him listen to it very slowly then if he understands he can make some decisions he makes about of decisions i make about so in regards to him i dont think there is any change in my decision making process then its more than fine i think twice before i make any decisions i compare my alternatives i consider lot of choices before i can actually make decision but as regards myself well some decisions i make as regards my own life i shared this with my wife theres no real need of sharing with my dad because even if i shared with him before tomorrow he forgets something like that so my decisions as regards myself my family i dont really share them with him because he dont really are remembers most of those things few ones that actually you know but you know real issues as regarding my decision making process i dont share that with him there is no change you know when you say change in decision making process maybe because im frustrated i make certain decisions because im angry i make certain decisions ive taught myself so much to be able to control all those calm myself down take it through listen to good music do something that just you know its little stressful now then when im come when im settled i can now think my way out of making very good decision because when you make decisions when you are annoyed most times it is end of time there are no good decisions because at that point i wont say youve lost your mind but you are totally out of yourself such situation might be really really terrible have nasty consequences so ive taught myself how to control them yeah that that is definitely true thats definitely true caregiving it sure it doesnt clash with you stuffs especially critical visits to hospitals so i make sure any vacation something doesnt tamper with that well about location i have home here so i dont see any circumstance of me you know moving out of this area for at least for next years so but if there would be maybe case maybe any circumstance that would actually need relocation movement i think there even would definitely be barrier because we have to actually transfer hospitals then get stable around place where we are feed them with all previous information they need to know then continue doing it there because it definitely is factor i would consider before i make such kinds of huge decisions you know decisions that would really affect him like me going on vacation locating going for holidays somewhere something it is major function that i have to consider ok now commitment page yeah definitely professional commitment yes eversource yeah self keep practicing yeah manage daily stress describe yourself here properties past weeks might stress of caregiving share strategies ok well selfcare practices like i said sometimes it gets very frustrating you know sometimes some things you tell him you forget its really annoying because sometimes its annoying definitely any normal person will get annoyed with some things like i said in previous recordings i have taught myself to manage these stresses it wasnt days job two years job three years job its been over years now so i go for walk when im having when im feeling stress you know having gone to my full time job makes lot of difficulties stuffs problems every other thing im coming back then i just want peace then im still having lot of things to deal with you know frustration sets in terrible mood swings anger every other thing so i learned to take walk you know once its not that its in critical situation where i need to be there i will just take walk i just go to my music room put on my earbuds listen to music play piano do something that would ease my stress i just even go to sitting room just watch netflix just laugh laugh out sometimes then is stress away so some of strategies have actually been employing sure i go away from that then sometimes i just you know i just try to cope with it i makes decisions not to get annoyed you know some things are supposed to make you annoyed then to see why am i why am i why am i even getting annoyed for no reason listen isnt something much that should get me annoyed then i just flush out thought of being annoyed then take it as something normal so i think those are some of major strategies i have employed as regards coping with daily stresses every other stuff how frequently ill say ill say majorly five days week five days i got my job definitely very stressful i dont even know that i should have done that then you prepare you want to eat this food then you make it then you bring it he doesnt want to eat it anymore he wants to eat something else you know lot of those things come up those are just few of examples its very stressful very annoying thats fifth one yeah factors such as professional commitment financial constraints yes our professional commitment definitely you know there was time i should you know have i my company was planning to actually sponsor me on trip to i think to united kingdom you know for seminar some other fellowship then for some other knowledge professional stuffs it was meant to be two weeks then i found way to get someone to stay with him every other thing it just fell apart i wasnt able to go it was really painful at that moment at that moment i you know just had to back out of opportunity that i had been waiting all my life for then it was frustrating terrible yeah it is what it is i have gotten something close that now so it doesnt pin me so much when i think of it so lot of professional commitments you know sometimes i am supposed to do over some over time just to get some extra cash then i just cant i just have to be dashing out of office money time because i have someone im caregiving you know its really really frustrating then you get home you meet some other stress some other things frustrating so i would say professional commitment care given standards barrier between lot of professional commitments as far as im concerned then financial constraints health challenges well financial constraints for me at this moment im im above moderate in very good salary my father also you know hes worked some things down for himself so he has his health insurance some other things that basically covered by job things he has done while he was still active so i dont really have support care about financial stuff it is well available so i wont say financial constraints is really any problem then health changes well sometimes i also fall sick then sick person still caring for sick person so i try my as best as much as i as i can not to fall sick i get distracted get lot of distraction lot lots of distraction you know sometimes he just makes some emergency call then you pick up you be like whats up says i just want to hear your voice you know that would be really annoying like you call me five times just want to hear my voice for what then im just you know i see your call im panicking now maybe something is wrong i just have to pick it up you know sometimes you see your call you know my brain say oh im busy you just shoot them text im busy ill call you later then thats all when you are done with job you call them but you see call you know it you know is someone ok given for so you just have to pick it up then you say ohh im busy at my job some other things then he doesnt hear he keeps calling so i get distracted lot yes definitely there are some positions i want us to be promoted to but its going to definitely hit hit into time of my care given so ive declined few of those offers then i hope it gets very very much more better soon then i can have less hours care given then maybe take some professional you know promotions no i sleep well i sleep well eat good he sleeps very he sleeps very early he wakes up late no no none of those ok do you sometimes feel concerned about what future holds for you in room definitely i definitely think about that i definitely think about that ive table that you know in family meetings some other stuff so you know no one is willing to take responsibility everyones busy everyone is doing this that it just feels like i just have to keep doing this forever then i think that well ive actually declined lot of professional things i should have you know gotten promoted getting costing me more money getting me you know some other things then this cake even is staying as barrier some other things you know just thinking about some other things so i definitely have thoughts most of time what future holds for me in this role because if it continues like this for long time you know i would have to decline lot of offers along line i might still be in same position for years so i consider that then im hoping very soon that one actually have enough finances we can actually transfer him to stable you know professional home where we have professional caregivers stuff like that but utmost prayer is that his conditions improve then we actually have less hours of caregiving then we are still caregivers that day but we have less hours because he cannot do many things by himself well doctors are promised that that is possibility in nearest future we are also hoping that god if that is possible but if that doesnt work out then at some point i wont be considering i would be considering professional caregiving homes so i guess thats it about that well truth is if i have someone someone else if we can run something like shift when im active for these two days week then hes active for another two days match for another two days im asking for hours day then he takes other hours you know something like that it would ease me of lot of stress lot of burdens then if possibly if we have enough finances we can just move him to professional place you know those ones they dont see it as task theyve been trained for that then they do it to any living so thats their job they dont have something else to stop in them so i think those might be two great options definitely definitely i think about that by percent of time first of all its financial basis then also weve had lot of stories about professional caregivers you know neglect terrible happenings that weve had that doesnt want he weve actually brought up in some meetings where family is willing to donate then get that done but he himself doesnt want that he says if we try that he gets escaped from there hes gonna run off do some of that stuffs you know its really hard then we also we are concerned about risk so thats why were not really implemented he forgets lot very frequently no he doesnt forget me he doesnt forget me he knows me he knows me mostly forget some other family members but i have stranger in this house its trying to come to front door doing this that you know ive had calls like that when my wife you know my wife was back at her job then he called me up ohh john but hes not aggressive towards them he just wants to know who is who what is what im sure hes safe i would say progressive out to neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADJ\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"single past few positive negative difficult positive financial positive few past past other more alone only few financial first selfcare past few daily helpful steady ok caring happy ok social asleep sure sorry ill inside past few such professional financial special financial buoyant fair fair fair enough least little tired much tired caregiver ill sure ill awake more more key concerned more concerned ill financial old stressful\",\n          \"old major past few about weak fine basic sure sure least sure sure sure sure little little sure necessary little normal responsible most ok past few lesser full tough tough little hard difficult new hard tough hard past few little easier willing extra sure ok fine past few hard few other own loud next easier ok more most most free better more more able little sometime most annoyed happy lively cold other lively better other little more more negative terrible alternative new much fun other useful remote other real real real able few more fine own real most few real frustrated certain angry certain much able calm good little stressful good most good such terrible nasty true true sure critical sure least next stable previous such huge major professional daily past selfcare frustrating annoying annoying normal previous full other terrible other critical sure annoyed much annoyed normal major daily other ill ill stressful few stressful annoying fifth such professional financial professional other other professional other able painful frustrating terrible close professional extra frustrating other other frustrating professional professional concerned financial financial moderate good other active financial available financial sick sick sick much sick distracted annoying wrong busy busy ill ok busy other distracted few less professional good concerned other willing busy professional more other other other most long same enough stable professional professional utmost less less many well nearest possible professional well active active other enough professional great financial professional neglect terrible willing hard concerned other stranger aggressive sure safe neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"i m alexia bonnie years single i m living with my parents i stay with my parents as who i does i do care given with yes i care for them very well mother she is years it was five years ago i ve been caring for her i am i am only caregiver for her share how you have been feeling in past few weeks while taking care of your loved one with dementia tell us about any moment whether positive challenging that stand out to you it has been negative life for me that s reduced my parting my my my studies everything about me so it has been difficult life life for me going to parties i m going to school too i have stopped schools i have been taking care of my mother i have stopped school there is no positive moment in financial aspects i do nt have any money to take care of her again like whenever i m cooking she will be screaming shouting yelling i will leave that to my meter again to take care of her no no positive moment ok describe ok giving assisting you about wellbeing past few weeks regarding your relationship with family friends comics to internet changes shifts relationships question too i have not i have not noticed any changes it has been way i have been given my life for past five years yep my family friends have run away because i m taking care of my mother so i m i m only one with her now no no no no sorry i ca nt hear you no it does nt affect me oh my communication my communication my attention has been shot with my family friends my colleagues in world in school too i invite only one of my friends has told by me for past four years five years so even if i should call her call her she will take like two to three days before she come to me yes yes i ca nt hear you please please repeat i ca nt hear you yes sorry question right my family i i told you other time but my family friends are no more they have they have gone they left me alone its only one of my friends that stay with me whenever i call her she used to take three to four days to come ok over past few weeks have you kids are not engineers intention making process you yes please my decision making has changed due to food i eat at home financial everything because of of my mothers sickness yes yes i do think about her i have to put her into consideration first number four question describe your selfcare practices in past few weeks to manage daily stresses of caregiving share your strategy strategies that have been particularly helpful in coping with steady stress of caregiving ok time i cook for her time i do i do take care of her time of caring time of management time of making her happy that s ok then that s what i can say for that number four question please i go on social media will i surf internet to rest i used to rest whenever i take care of us i whenever she is asleep i used to sleep too i used to take rest my make sure i wake up before i used to sleep very well before go out go to schools go to clubs i used to party very well but now i do nt used to do that again i used to drive i i will put on car drive out wherever whenever wherever i m going sorry i ca nt hear you no nobody either its to go out i do nt used to leave her at home go out i go with i go out with her ill put her inside car go out nobody to stay with her in past few weeks of earning factors such as professional commitment financial constraints for health challenges influence how you fees based on this these special therapists are attention caregiver used to allow her to allow person to come but now there is no financial support again from anybody so i had to go i had to carry out to government hospital for caring yes there is no changes cause i do nt have any money i m not i m not financially buoyant now sorry i ca nt hear yes i ca nt hear you fair enough i m i m fair enough fair enough health my is nt my home my mothers health my health at least i m copying little i get tired stress is too much for me i get tired every now then i m because i m taking care of my mother because i m i m caregiver to my mother i ve not seen any support from anyone i work remotely just work for three hours remaining hours is for taking care of her no he s answer my mother i m doing it because of my mother ill just make sure that i have given her her drugs her food then ill start working it has reduced my wages like like weeks ago now when i was working she she was awake i had to stop work when i was what what i had to stop what i was doing then attended attend to her this has affected me in lot of ways what do i do ah i used to give her more than more than hours as key given do you sometimes feel concerned about what future holds for you in that room if so could you share more about it what kind of help support will bear for you economist question as caregiver do you sometimes feel concerned about future what future holds for you in that if so yes yes yes because i need partner i will still have ill i m going to give birth have my husband get married one day so i need assistant i need partner too yes no no no no no please repeat question i ca nt hear you yes yes i m here i m here i need to dedicate my time to her voting of attention to financial support i ca nt remember not really i ca nt remember anything now like moment i i went to go look for some jobs to do she needs my attention so i had to attend to her before going she can remember me i show her some old videos of ours some pictures lots more she she react amazingly she goes into her room when someone comes in as in she as she reacts amazingly sometimes not every time no no no she does nt no she remembers me no no no i do nt used to allow her to go outside alone two times in week no no not him stressful\",\n          \"ok my name is yeah my name is john smith i am years old i am child to you know person with dementia is my father ok i m only one who is major caregiver ok answering question one well for past few weeks yeah its about years to years he s why so weak yeah i m i m always with him he stays with me we stay together so before going to my job i ensure he s fine i provide every basic things he needs you know he slowed his his emails his phone calls voicemails he has sure everything are kept in check sure he s using his medication they are all set before i go to my job at my job i always calling i calling at least twice to check on him to make sure he s doing fine make sure he s not having any reaction side effects to medication make sure he s resting one is supposed to make sure he s doing little exercise that has been prepared for him you know when i m back also i take him we go for walk take stroll around we do little exercise sometimes we go to church together there sure he also eats well eat fruits eats necessary things those use medication those little exercise then also on days of his visit to hospital sure i take him there on time i m always saying while he s in doctor we are done you know come back home so its just like normal thing you do for your child so it i immediately i m responsible for most of things ok someone says that ok well for past few weeks i would say pressure is much more lesser than before then i had you know when we first started it was lot for me to taking balancing being caregiver also having full time job its really really tough its really tough then being at entry level someone with little no you know superiority i have buses which i m also under their command you know its really hard to have my wish in time like that so then also its its always very difficult coping with new development you know things your father can do before easily before you find it you say that he s having hard time doing them you always just have to be around ensuring that it does it right so its always very tough to take in its really hard to believe that this is happening so for for past few weeks ice after that i m finding it little bit more easier because i ve let it become part of me i ve let it become something i do you know not because i want to receive award for some you know some people work because they just want to get pay some people do some things because they just want to you know receive profits from it but when you do something because of all of you have for person you do nt count it as something that even if its not reciprocated well you do nt see it as anything so i ve learned to teach myself to do it because i love my father my parents i would i m willing to go extra mile to make sure they re ok they re fine because they ve also sacrificed lot for me so for past few weeks i have made it my habits you know something i do without being for something i do without seeing it that s hard job though there s lot of challenge definitely lot of challenge tell him something he forgets it easily has few reactions some things you did yesterday you can remember some things you know lot of things lot of challenges but i ve learned to just calm down you know sometimes when its overwhelming i just take walk just listen to music just do something to calm me myself down because i can not be transferring aggression to him i can not show any sign of no anger any other things because it would really really affect his own wellbeing so i rather would rather take walk on his throat rather just turn my earbuds on listen to loud music just do something to just chill off before i can actually think on what next to do so i would say i m really coping nicely i m finding strategies to make it much more easier for me so that s how that is ok well relationship with friends family colleagues definitely there is shift i spend more time at home apart from my job apart from my job you know most times then i would love to socialize you know visit friends go to watch game go to at club go to lottery houses you know i spent my most of my free times there my weekends you know i m socializing i m hanging out i m doing lot of stuff sports now i have to spend there with my parents my dad because he needs care everything is getting better though but he needs care so that s affected my relationship with my friends well it makes me my wife have much more time together since i m spending more time at home with my father she s always around too so but with my friends that s really severed relationship we do lot of call video calls you know voice calls to kind of compensate for may not being able to show up there sometimes that some occasions will clash with days he has to go to hospital i just have to cancel occasion you know so its really done little to that my friends my colleagues you know my colleague maybe having birthday celebration at his home he s having occasion its classes with sometime by time i have to just be with my dad so most of them do actually understand they understand my situation they do nt get annoyed but definitely i would say it has really affected it has made me more introvert no staying indoors just loving things i can do indoors you know i only go out when i have to apart from my job sometimes i take my dad also sees to see game because he loves basketball so we go to watch some basketball sometimes makes him more happy makes him lively you know you see him celebrate him when he sees says he hook he goes cold some other things makes him more lively you know it adds makes health better some other things so that s pretty much how when i go out then relationship with my friends colleagues it has done little damage to it definitely definitely it is it is i it has it is about where its stopping me from going out its making me spend more time at home spend more time with my dad just ensuring that things are going as it should so but i do nt see that as you know when you people say barrier you know its something very negative something terrible something you do nt want to but it is what it is now i m not seeing it as barrier i m just saying that is that how can i describe it as alternative you know i m learning new way of life instead of being that you know extroverts talk so much going out partying having so much fun spending money wasting money wasting time doing some other things i now taking all those energies transfer it into something useful apart from while i m even caregiving i have some remote things i do i trade crypto i do some other things so i want to say its barrier anymore it has taught me how to actually invest in myself do things while i m at home so that also helped me in way ok well in my decision making process i think no real change no real change no real change any decision i need to make you know in regards to him sometimes he actually is able to make few decisions sometimes you know explaining some things to him he does nt understand we write it down let him greet we play it let him listen to it very slowly then if he understands he can make some decisions he makes about of decisions i make about so in regards to him i do nt think there is any change in my decision making process then its more than fine i think twice before i make any decisions i compare my alternatives i consider lot of choices before i can actually make decision but as regards myself well some decisions i make as regards my own life i shared this with my wife there s no real need of sharing with my dad because even if i shared with him before tomorrow he forgets something like that so my decisions as regards myself my family i do nt really share them with him because he do nt really are remembers most of those things few ones that actually you know like maybe ah ohh its your granddaughter birthday its your grandsons birthday something like that ohh its your its your wifes birthday its my birthday you know things like that that they re just for moment so we share those with him but you know real issues as regarding my decision making process i do nt share that with him there is no change you know when you say change in decision making process maybe because i m frustrated i make certain decisions because i m angry i make certain decisions i ve taught myself so much to be able to control all those calm myself down take it through listen to good music do something that just you know its little stressful now then when i m come when i m settled i can now think my way out of making very good decision because when you make decisions when you are annoyed most times it is end of time there are no good decisions because at that point i wo nt say you ve lost your mind but you are totally out of yourself such situation might be really really terrible have nasty consequences so i ve taught myself how to control them yeah that that is definitely true that s definitely true caregiving yes definitely it does affect it affects those decisions you know i before i go for any vacation of stuff i have to plan it very well it sure it does nt clash with you stuffs especially critical visits to hospitals so i make sure any vacation something does nt tamper with that well about location i have home here so i do nt see any circumstance of me you know moving out of this area for at least for next years so i love this place i settled in i think i m doing fine so but if there would be maybe case maybe any circumstance that would actually need relocation movement i think there even would definitely be barrier because we have to actually transfer hospitals then get stable around place where we are feed them with all previous information they need to know then continue doing it there because it definitely is factor i would consider before i make such kinds of huge decisions you know decisions that would really affect him like me going on vacation locating going for holidays somewhere something it is major function that i have to consider ok now commitment page yeah definitely professional commitment yes eversource definitely they have affected some things with us ok yeah self keep practicing yeah manage daily stress describe yourself here properties past weeks might stress of caregiving share strategies ok well selfcare practices like i said sometimes it gets very frustrating you know sometimes some things you tell him you forget its really annoying because sometimes its annoying definitely any normal person will get annoyed with some things like i said in previous recordings i have taught myself to manage these stresses it was nt days job two years job three years job its been over years now so i go for walk when i m having when i m feeling stress you know having gone to my full time job makes lot of difficulties stuffs problems every other thing i m coming back then i just want peace then i m still having lot of things to deal with you know frustration sets in terrible mood swings anger every other thing so i learned to take walk you know once its not that its in critical situation where i need to be there i will just take walk i just go to my music room put on my earbuds listen to music play piano do something that would ease my stress i just even go to sitting room just watch netflix just laugh laugh out sometimes then is stress away so some of strategies have actually been employing sure i go away from that you know i i go away from where he is just try to ease with stress then then sometimes then sometimes i just you know i just try to cope with it i makes decisions not to get annoyed you know some things are supposed to make you annoyed then to see why am i why am i why am i even getting annoyed for no reason listen is nt something much that should get me annoyed then i just flush out thought of being annoyed then take it as something normal so i think those are some of major strategies i have employed as regards coping with daily stresses every other stuff how frequently ill say ill say majorly five days week five days i got my job definitely very stressful well i would say is about him keeping to his routine he knows what he should be doing at this time he knows what he should be doing at that time then you ask him have you done this ohh i ve done it then you find out he s not done it ok he has call he has check up call from hospital while i m at my job he s not he s not picking them up he s not answering he say oh have you done this say ohh i do nt even know that i should have done that then you prepare you want to eat this food then you make it then you bring it he does nt want to eat it anymore he wants to eat something else you know lot of those things come up those are just few of examples its very stressful very annoying that s fifth one right yeah yeah factors such as professional commitment financial constraints yes our professional commitment definitely you know there was time i should you know have i my company was planning to actually sponsor me on trip to i think to united kingdom you know for seminar some other fellowship then for some other knowledge professional stuffs it was meant to be two weeks then i found way to get someone to stay with him every other thing it just fell apart i was nt able to go it was really painful at that moment at that moment i you know just had to back out of opportunity that i had been waiting all my life for then it was frustrating terrible well yeah it is what it is i have gotten something close that now so it does nt pin me so much when i think of it so lot of professional commitments you know sometimes i am supposed to do over some over time just to get some extra cash then i just ca nt i just have to be dashing out of office money time because i have someone i m caregiving you know its really really frustrating then you get home you meet some other stress some other things frustrating so i would say professional commitment care given standards barrier between lot of professional commitments as far as i m concerned then financial constraints health challenges well financial constraints for me at this moment well i thank god i think i m i m i m above moderate in very good salary my father also you know he s worked some things down for himself so he has his health insurance some other things that basically covered by job things he has done while he was still active so i do nt really have support care about financial stuff it is well available so i wo nt say financial constraints is really any problem then health changes well sometimes i also fall sick then sick person still caring for sick person so i try my as best as much as i as i can not to fall sick but when i do i well my wife actually takes takes responsibility of doing what i ve been doing so i think that s basically it i get distracted get lot of distraction lot lots of distraction you know sometimes he just makes some emergency call then you pick up you be like what s up says i just want to hear your voice you know that would be really annoying like you call me five times just want to hear my voice for what then i m just you know i see your call i m panicking now maybe something is wrong i just have to pick it up you know sometimes you see your call you know my brain say oh i m busy you just shoot them text i m busy ill call you later then that s all when you are done with job you call them but you see call you know it you know is someone ok given for so you just have to pick it up then you say ohh i just want to hear your voice why just want to do this then you be like do nt call me like this when i see your call i have to pick up because of this that do nt just call because when i hear my voice i m busy at my job some other things then he does nt hear he keeps calling so i get distracted lot so but its part of job of caregiving definitely well yes definitely there are some positions i want us to be promoted to but its going to definitely hit hit into time of my care given so i ve declined few of those offers then i hope it gets very very much more better soon then i can have less hours care given then maybe take some professional you know promotions no i sleep well i sleep well eat good he sleeps very he sleeps very early he wakes up late so i hardly have any issues at night i sleep well for me for him no no no no none of those ok do you sometimes feel concerned about what future holds for you in room yeah definitely i definitely think about that i definitely think about that i ve table that you know in family meetings some other stuff so you know no one is willing to take responsibility everyones busy everyone is doing this that it just feels like i just have to keep doing this forever then i think that well i ve actually declined lot of professional things i should have you know gotten promoted getting costing me more money getting me you know some other things then this cake even is staying as barrier some other things you know just thinking about some other things so i definitely have thoughts most of time what future holds for me in this role because if it continues like this for long time you know i would have to decline lot of offers along line i might still be in same position for years so i consider that then i m hoping very soon that one actually have enough finances we can actually transfer him to stable you know professional home where we have professional caregivers stuff like that but utmost prayer is that his conditions improve then we actually have less hours of caregiving then we are still caregivers that day but we have less hours because he can not do many things by himself well doctors are promised that that is possibility in nearest future we are also hoping that god if that is possible but if that does nt work out then at some point i wo nt be considering i would be considering professional caregiving homes so i guess that s it about that well truth is if i have someone someone else if we can run something like shift when i m active for these two days week then he s active for another two days match for another two days i m asking for hours day then he takes other hours you know something like that it would ease me of lot of stress lot of burdens then if possibly if we have enough finances we can just move him to professional place you know those ones they do nt see it as task they ve been trained for that then they do it to any living so that s their job they do nt have something else to stop in them so i think those might be two great options ok yeah definitely definitely i think about that by percent of time first of all its financial basis then also we ve had lot of stories about professional caregivers you know neglect terrible happenings that we ve had that does nt want he he he kicks he kicks against it he does nt want it we ve actually brought up in some meetings where family is willing to donate then get that done but he himself does nt want that he says if we try that he gets escaped from there he s gon na run off do some of that stuffs you know its really hard he does nt want it then we also we are concerned about risk so that s why were not really implemented he forgets lot very frequently ohh me no he does nt forget me he does nt forget me he knows me he knows me mostly forget some other family members but not not me not me does nt remember them yeah definitely like oh what are you what are you looking for you know sometimes like oh oh john i have stranger in this house its trying to come to front door doing this that you know i ve had calls like that when my wife you know my wife was back at her job then he called me up ohh john i have this woman lady at my door i do nt know what she s looking for can you call cops can you do this i m like its my wife for gods sake so you have issues like that so but he s not aggressive towards them he just wants to know who is who what is what i m sure he s safe i would say progressive out to neutral yeah so i do nt read it read it well i feel i might share my experiences then i was thinking maybe there are some resources that can actually help me caregiving journey maybe something like that would also be shared during meeting so those are things i m looking for\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Read the CSV files\n",
        "phq_df = pd.read_csv('PHQ_preprocessed.csv')\n",
        "narrative_df = pd.read_csv('preprocessed_narrative.csv')\n",
        "\n",
        "narrative_df_last_three = narrative_df.iloc[:, -3:]\n",
        "merged_df = pd.concat([phq_df, narrative_df_last_three], axis=1)\n",
        "merged_df.to_csv('Narrative_Plus_PHQ.csv', index=False)\n",
        "\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge ZBI_demographic to Narrative data"
      ],
      "metadata": {
        "id": "pNM81zqZy3fX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "162da457-10cf-43b7-fd99-d04ba4b14c25",
        "id": "USUEab_Xy0Gp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Participant ID  Age  Sex  Race  Ethnicity  Location  Employment  Education  \\\n",
              "0               1    0    0     0          0         0           0          0   \n",
              "1               2    0    0     0          0         1           0          0   \n",
              "2               3    0    0     0          0         0           1          0   \n",
              "3               4    0    0     0          0         0           0          0   \n",
              "4               5    0    0     0          0         1           1          0   \n",
              "\n",
              "   Income  Health Insurance  Relationship to Loved One  Years Caring  \\\n",
              "0       0                 0                          0             0   \n",
              "1       1                 0                          0             1   \n",
              "2       1                 1                          0            10   \n",
              "3       0                 0                          1            10   \n",
              "4       1                 0                          1            10   \n",
              "\n",
              "   Daily Caregiving Hours  ZBI_score  \\\n",
              "0                       0          1   \n",
              "1                       1          0   \n",
              "2                       1          1   \n",
              "3                       0          1   \n",
              "4                       0          1   \n",
              "\n",
              "                                                 ACD  \\\n",
              "0  yeah can i read questions first ok uh my name ...   \n",
              "1  ok ok so my name is jonathan im fergal years o...   \n",
              "2  alright my full name is brian brian hemsworth ...   \n",
              "3  yeah my name is montana franklin im years old ...   \n",
              "4  ok im victor daniel my name is victor daniel y...   \n",
              "\n",
              "                                                 ADJ  \\\n",
              "0  palma real few artificial helpful loved many a...   \n",
              "1  fergal old biological old close same primary s...   \n",
              "2  full old easy more much ill best problematic f...   \n",
              "3  old dead easy ready same same same clinical se...   \n",
              "4  old challenging past ok social religious posit...   \n",
              "\n",
              "                                                 UNI  \n",
              "0  yeah can i read questions first ok uh my name ...  \n",
              "1  ok ok so my name is jonathan i m fergal years ...  \n",
              "2  alright my full name is brian brian hemsworth ...  \n",
              "3  yeah my name is montana franklin i m years old...  \n",
              "4  ok i m victor daniel my name is victor daniel ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f8d9aed-7a77-49cf-856c-ce9ee9f8abf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Race</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Location</th>\n",
              "      <th>Employment</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "      <th>Health Insurance</th>\n",
              "      <th>Relationship to Loved One</th>\n",
              "      <th>Years Caring</th>\n",
              "      <th>Daily Caregiving Hours</th>\n",
              "      <th>ZBI_score</th>\n",
              "      <th>ACD</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>UNI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>yeah can i read questions first ok uh my name ...</td>\n",
              "      <td>palma real few artificial helpful loved many a...</td>\n",
              "      <td>yeah can i read questions first ok uh my name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ok ok so my name is jonathan im fergal years o...</td>\n",
              "      <td>fergal old biological old close same primary s...</td>\n",
              "      <td>ok ok so my name is jonathan i m fergal years ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>alright my full name is brian brian hemsworth ...</td>\n",
              "      <td>full old easy more much ill best problematic f...</td>\n",
              "      <td>alright my full name is brian brian hemsworth ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>yeah my name is montana franklin im years old ...</td>\n",
              "      <td>old dead easy ready same same same clinical se...</td>\n",
              "      <td>yeah my name is montana franklin i m years old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ok im victor daniel my name is victor daniel y...</td>\n",
              "      <td>old challenging past ok social religious posit...</td>\n",
              "      <td>ok i m victor daniel my name is victor daniel ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f8d9aed-7a77-49cf-856c-ce9ee9f8abf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f8d9aed-7a77-49cf-856c-ce9ee9f8abf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f8d9aed-7a77-49cf-856c-ce9ee9f8abf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3eddc74b-add6-4625-b2b3-913492058cbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3eddc74b-add6-4625-b2b3-913492058cbe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3eddc74b-add6-4625-b2b3-913492058cbe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df",
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 65,\n  \"fields\": [\n    {\n      \"column\": \"Participant ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 1,\n        \"max\": 68,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          57,\n          64,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Race\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ethnicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Employment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Health Insurance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Relationship to Loved One\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Years Caring\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Daily Caregiving Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZBI_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ACD\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"im alexia bonnie years single im living with my parents i stay with my parents as who i does i do care given with i am i am only caregiver for her share how you have been feeling in past few weeks while taking care of your loved one with dementia tell us about any moment whether positive challenging that stand out to you it has been negative life for me thats reduced my parting my my my studies everything about me so it has been difficult life life for me going to parties im going to school too i have stopped schools i have been taking care of my mother i have stopped school there is no positive moment in financial aspects i dont have any money to take care of her again like whenever im cooking she will be screaming shouting yelling i will leave that to my meter again to take care of her no no positive moment ok describe ok giving assisting you about wellbeing past few weeks regarding your relationship with family friends comics to internet changes shifts relationships question too i have not i have not noticed any changes it has been way i have been given my life for past five years i invite only one of my friends has told by me for past four years five years i i told you other time but my family friends are no more they have they have gone they left me alone its only one of my friends that stay with me whenever i call her she used to take three to four days to come ok over past few weeks yes please my decision making has changed due to food i eat at home financial everything because of of my mothers sickness yes i do think about her i have to put her into consideration first number four question describe your selfcare practices in past few weeks to manage daily stresses of caregiving share your strategy strategies that have been particularly helpful in coping with steady stress of caregiving ok time i cook for her time i do i do take care of her time of caring time of management time of making her happy thats ok then thats what i can say for that number four question please i go on social media will i surf internet to rest i used to rest whenever i take care of us i whenever she is asleep i used to sleep too i used to take rest my make sure i wake up before i used to sleep very well before go out go to schools go to clubs i used to party very well but now i dont used to do that again i used to drive i i will put on car drive out wherever whenever wherever im going sorry i dont used to leave her at home go out i go with i go out with her ill put her inside car go out nobody to stay with her in past few weeks of earning factors such as professional commitment financial constraints for health challenges influence how you fees based on this these special therapists are attention caregiver used to allow her to allow person to come but now there is no financial support again from anybody im not financially buoyant now yes i cant hear you fair enough im im fair enough fair enough health my isnt my home my mothers health my health at least im copying little i get tired stress is too much for me i get tired every now then im because im taking care of my mother because im im caregiver to my mother ive not seen any support from anyone i work remotely just work for three hours remaining hours is for taking care of her no hes answer my mother im doing it because of my mother ill just make sure that i have given her her drugs her food then ill start working it has reduced my wages like like weeks ago now when i was working she she was awake what do i do ah i used to give her more than more than hours as key given do you sometimes feel concerned about what future holds for you in that room if so could you share more about it what kind of help support will bear for you economist question as caregiver do you sometimes feel concerned about future what future holds for you in that yes because i need partner i will still have ill im here i need to dedicate my time to her voting of attention to financial support i cant remember not really i cant remember anything now so i had to attend to her before going she can remember me i show her some old videos of ours some pictures lots more she she react amazingly she goes into her room when someone comes in as in she as she reacts amazingly sometimes not every time no no not him stressful\",\n          \"my name is john smith i am years old i am child to you know person with dementia is my father ok im only one who is major caregiver ok answering question one well for past few weeks yeah its about years to years hes why so weak so before going to my job i ensure hes fine i provide every basic things he needs you know he slowed his his emails his phone calls voicemails he has sure everything are kept in check sure hes using his medication they are all set before i go to my job at my job i always calling i calling at least twice to check on him to make sure hes doing fine make sure hes not having any reaction side effects to medication make sure hes resting one is supposed to make sure hes doing little exercise that has been prepared for him you know when im back also i take him we go for walk take stroll around we do little exercise sometimes we go to church together there sure he also eats well eat fruits eats necessary things those use medication those little exercise then also on days of his visit to hospital so its just like normal thing you do for your child i immediately im responsible for most of things ok someone says that ok well for past few weeks i would say pressure is much more lesser than before then i had you know when we first started it was lot for me to taking balancing being caregiver also having full time job its really really tough its really tough then being at entry level someone with little i have buses which im also under their command you know its really hard to have my wish in time like that so then also its its always very difficult coping with new development you know things your father can do before easily before you find it you say that hes having hard time doing them you always just have to be around ensuring that it does it right so its always very tough to take in its really hard to believe that this is happening so for for past few weeks ice after that im finding it little bit more easier because ive let it become part of me ive let it become something i do you know i would im willing to go extra mile to make sure theyre ok theyre fine because theyve also sacrificed lot for me so for past few weeks i have made it my habits you know something i do without being for something i do without seeing it thats hard job though theres lot of challenge definitely lot of challenge tell him something he forgets it easily has few reactions some things you did yesterday you can remember some things you know lot of things lot of challenges but ive learned to just calm down you know sometimes when its overwhelming i just take walk just listen to music just do something to calm me myself down because i cannot be transferring aggression to him i cannot show any sign of no anger any other things because it would really really affect his own wellbeing so i rather would rather take walk on his throat rather just turn my earbuds on listen to loud music just do something to just chill off before i can actually think on what next to do so i would say im really coping nicely im finding strategies to make it much more easier for me so thats how that is ok well relationship with friends family colleagues definitely there is shift i spend more time at home apart from my job apart from my job you know most times then i would love to socialize you know visit friends go to watch game go to at club go to lottery houses you know i spent my most of my free times there my weekends you know im socializing im hanging out im doing lot of stuff sports now i have to spend there with my parents my dad because he needs care everything is getting better though but he needs care so thats affected my relationship with my friends well it makes me my wife have much more time together since im spending more time at home with my father shes always around too so but with my friends thats really severed relationship we do lot of call video calls you know voice calls to kind of compensate for may not being able to show up there sometimes that some occasions will clash with days he has to go to hospital so its really done little to that my friends my colleagues you know my colleague maybe having birthday celebration at his home hes having occasion its classes with sometime by time i have to just be with my dad so most of them do actually understand they understand my situation they dont get annoyed so we go to watch some basketball sometimes makes him more happy makes him lively you know you see him celebrate him when he sees says he hook he goes cold some other things makes him more lively you know it adds makes health better some other things so thats pretty much how when i go out then relationship with my friends colleagues it has done little damage to it definitely i it has it is about where its stopping me from going out its making me spend more time at home spend more time with my dad just ensuring that things are going as it should but i dont see that as you know when you people say barrier you know its something very negative something terrible something you dont want to but it is what it is now im not seeing it as barrier im just saying that is that how can i describe it as alternative you know im learning new way of life instead of being that you know extroverts talk so much going out partying having so much fun spending money wasting money wasting time doing some other things i now taking all those energies transfer it into something useful apart from while im even caregiving i have some remote things i do i trade crypto i do some other things so i want to say its barrier anymore it has taught me how to actually invest in myself do things while im at home so that also helped me in way ok well in my decision making process i think no real change no real change no real change any decision i need to make you know in regards to him sometimes he actually is able to make few decisions sometimes you know explaining some things to him he doesnt understand we write it down let him greet we play it let him listen to it very slowly then if he understands he can make some decisions he makes about of decisions i make about so in regards to him i dont think there is any change in my decision making process then its more than fine i think twice before i make any decisions i compare my alternatives i consider lot of choices before i can actually make decision but as regards myself well some decisions i make as regards my own life i shared this with my wife theres no real need of sharing with my dad because even if i shared with him before tomorrow he forgets something like that so my decisions as regards myself my family i dont really share them with him because he dont really are remembers most of those things few ones that actually you know but you know real issues as regarding my decision making process i dont share that with him there is no change you know when you say change in decision making process maybe because im frustrated i make certain decisions because im angry i make certain decisions ive taught myself so much to be able to control all those calm myself down take it through listen to good music do something that just you know its little stressful now then when im come when im settled i can now think my way out of making very good decision because when you make decisions when you are annoyed most times it is end of time there are no good decisions because at that point i wont say youve lost your mind but you are totally out of yourself such situation might be really really terrible have nasty consequences so ive taught myself how to control them yeah that that is definitely true thats definitely true caregiving it sure it doesnt clash with you stuffs especially critical visits to hospitals so i make sure any vacation something doesnt tamper with that well about location i have home here so i dont see any circumstance of me you know moving out of this area for at least for next years so but if there would be maybe case maybe any circumstance that would actually need relocation movement i think there even would definitely be barrier because we have to actually transfer hospitals then get stable around place where we are feed them with all previous information they need to know then continue doing it there because it definitely is factor i would consider before i make such kinds of huge decisions you know decisions that would really affect him like me going on vacation locating going for holidays somewhere something it is major function that i have to consider ok now commitment page yeah definitely professional commitment yes eversource yeah self keep practicing yeah manage daily stress describe yourself here properties past weeks might stress of caregiving share strategies ok well selfcare practices like i said sometimes it gets very frustrating you know sometimes some things you tell him you forget its really annoying because sometimes its annoying definitely any normal person will get annoyed with some things like i said in previous recordings i have taught myself to manage these stresses it wasnt days job two years job three years job its been over years now so i go for walk when im having when im feeling stress you know having gone to my full time job makes lot of difficulties stuffs problems every other thing im coming back then i just want peace then im still having lot of things to deal with you know frustration sets in terrible mood swings anger every other thing so i learned to take walk you know once its not that its in critical situation where i need to be there i will just take walk i just go to my music room put on my earbuds listen to music play piano do something that would ease my stress i just even go to sitting room just watch netflix just laugh laugh out sometimes then is stress away so some of strategies have actually been employing sure i go away from that then sometimes i just you know i just try to cope with it i makes decisions not to get annoyed you know some things are supposed to make you annoyed then to see why am i why am i why am i even getting annoyed for no reason listen isnt something much that should get me annoyed then i just flush out thought of being annoyed then take it as something normal so i think those are some of major strategies i have employed as regards coping with daily stresses every other stuff how frequently ill say ill say majorly five days week five days i got my job definitely very stressful i dont even know that i should have done that then you prepare you want to eat this food then you make it then you bring it he doesnt want to eat it anymore he wants to eat something else you know lot of those things come up those are just few of examples its very stressful very annoying thats fifth one yeah factors such as professional commitment financial constraints yes our professional commitment definitely you know there was time i should you know have i my company was planning to actually sponsor me on trip to i think to united kingdom you know for seminar some other fellowship then for some other knowledge professional stuffs it was meant to be two weeks then i found way to get someone to stay with him every other thing it just fell apart i wasnt able to go it was really painful at that moment at that moment i you know just had to back out of opportunity that i had been waiting all my life for then it was frustrating terrible yeah it is what it is i have gotten something close that now so it doesnt pin me so much when i think of it so lot of professional commitments you know sometimes i am supposed to do over some over time just to get some extra cash then i just cant i just have to be dashing out of office money time because i have someone im caregiving you know its really really frustrating then you get home you meet some other stress some other things frustrating so i would say professional commitment care given standards barrier between lot of professional commitments as far as im concerned then financial constraints health challenges well financial constraints for me at this moment im im above moderate in very good salary my father also you know hes worked some things down for himself so he has his health insurance some other things that basically covered by job things he has done while he was still active so i dont really have support care about financial stuff it is well available so i wont say financial constraints is really any problem then health changes well sometimes i also fall sick then sick person still caring for sick person so i try my as best as much as i as i can not to fall sick i get distracted get lot of distraction lot lots of distraction you know sometimes he just makes some emergency call then you pick up you be like whats up says i just want to hear your voice you know that would be really annoying like you call me five times just want to hear my voice for what then im just you know i see your call im panicking now maybe something is wrong i just have to pick it up you know sometimes you see your call you know my brain say oh im busy you just shoot them text im busy ill call you later then thats all when you are done with job you call them but you see call you know it you know is someone ok given for so you just have to pick it up then you say ohh im busy at my job some other things then he doesnt hear he keeps calling so i get distracted lot yes definitely there are some positions i want us to be promoted to but its going to definitely hit hit into time of my care given so ive declined few of those offers then i hope it gets very very much more better soon then i can have less hours care given then maybe take some professional you know promotions no i sleep well i sleep well eat good he sleeps very he sleeps very early he wakes up late no no none of those ok do you sometimes feel concerned about what future holds for you in room definitely i definitely think about that i definitely think about that ive table that you know in family meetings some other stuff so you know no one is willing to take responsibility everyones busy everyone is doing this that it just feels like i just have to keep doing this forever then i think that well ive actually declined lot of professional things i should have you know gotten promoted getting costing me more money getting me you know some other things then this cake even is staying as barrier some other things you know just thinking about some other things so i definitely have thoughts most of time what future holds for me in this role because if it continues like this for long time you know i would have to decline lot of offers along line i might still be in same position for years so i consider that then im hoping very soon that one actually have enough finances we can actually transfer him to stable you know professional home where we have professional caregivers stuff like that but utmost prayer is that his conditions improve then we actually have less hours of caregiving then we are still caregivers that day but we have less hours because he cannot do many things by himself well doctors are promised that that is possibility in nearest future we are also hoping that god if that is possible but if that doesnt work out then at some point i wont be considering i would be considering professional caregiving homes so i guess thats it about that well truth is if i have someone someone else if we can run something like shift when im active for these two days week then hes active for another two days match for another two days im asking for hours day then he takes other hours you know something like that it would ease me of lot of stress lot of burdens then if possibly if we have enough finances we can just move him to professional place you know those ones they dont see it as task theyve been trained for that then they do it to any living so thats their job they dont have something else to stop in them so i think those might be two great options definitely definitely i think about that by percent of time first of all its financial basis then also weve had lot of stories about professional caregivers you know neglect terrible happenings that weve had that doesnt want he weve actually brought up in some meetings where family is willing to donate then get that done but he himself doesnt want that he says if we try that he gets escaped from there hes gonna run off do some of that stuffs you know its really hard then we also we are concerned about risk so thats why were not really implemented he forgets lot very frequently no he doesnt forget me he doesnt forget me he knows me he knows me mostly forget some other family members but i have stranger in this house its trying to come to front door doing this that you know ive had calls like that when my wife you know my wife was back at her job then he called me up ohh john but hes not aggressive towards them he just wants to know who is who what is what im sure hes safe i would say progressive out to neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADJ\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"single past few positive negative difficult positive financial positive few past past other more alone only few financial first selfcare past few daily helpful steady ok caring happy ok social asleep sure sorry ill inside past few such professional financial special financial buoyant fair fair fair enough least little tired much tired caregiver ill sure ill awake more more key concerned more concerned ill financial old stressful\",\n          \"old major past few about weak fine basic sure sure least sure sure sure sure little little sure necessary little normal responsible most ok past few lesser full tough tough little hard difficult new hard tough hard past few little easier willing extra sure ok fine past few hard few other own loud next easier ok more most most free better more more able little sometime most annoyed happy lively cold other lively better other little more more negative terrible alternative new much fun other useful remote other real real real able few more fine own real most few real frustrated certain angry certain much able calm good little stressful good most good such terrible nasty true true sure critical sure least next stable previous such huge major professional daily past selfcare frustrating annoying annoying normal previous full other terrible other critical sure annoyed much annoyed normal major daily other ill ill stressful few stressful annoying fifth such professional financial professional other other professional other able painful frustrating terrible close professional extra frustrating other other frustrating professional professional concerned financial financial moderate good other active financial available financial sick sick sick much sick distracted annoying wrong busy busy ill ok busy other distracted few less professional good concerned other willing busy professional more other other other most long same enough stable professional professional utmost less less many well nearest possible professional well active active other enough professional great financial professional neglect terrible willing hard concerned other stranger aggressive sure safe neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"i m alexia bonnie years single i m living with my parents i stay with my parents as who i does i do care given with yes i care for them very well mother she is years it was five years ago i ve been caring for her i am i am only caregiver for her share how you have been feeling in past few weeks while taking care of your loved one with dementia tell us about any moment whether positive challenging that stand out to you it has been negative life for me that s reduced my parting my my my studies everything about me so it has been difficult life life for me going to parties i m going to school too i have stopped schools i have been taking care of my mother i have stopped school there is no positive moment in financial aspects i do nt have any money to take care of her again like whenever i m cooking she will be screaming shouting yelling i will leave that to my meter again to take care of her no no positive moment ok describe ok giving assisting you about wellbeing past few weeks regarding your relationship with family friends comics to internet changes shifts relationships question too i have not i have not noticed any changes it has been way i have been given my life for past five years yep my family friends have run away because i m taking care of my mother so i m i m only one with her now no no no no sorry i ca nt hear you no it does nt affect me oh my communication my communication my attention has been shot with my family friends my colleagues in world in school too i invite only one of my friends has told by me for past four years five years so even if i should call her call her she will take like two to three days before she come to me yes yes i ca nt hear you please please repeat i ca nt hear you yes sorry question right my family i i told you other time but my family friends are no more they have they have gone they left me alone its only one of my friends that stay with me whenever i call her she used to take three to four days to come ok over past few weeks have you kids are not engineers intention making process you yes please my decision making has changed due to food i eat at home financial everything because of of my mothers sickness yes yes i do think about her i have to put her into consideration first number four question describe your selfcare practices in past few weeks to manage daily stresses of caregiving share your strategy strategies that have been particularly helpful in coping with steady stress of caregiving ok time i cook for her time i do i do take care of her time of caring time of management time of making her happy that s ok then that s what i can say for that number four question please i go on social media will i surf internet to rest i used to rest whenever i take care of us i whenever she is asleep i used to sleep too i used to take rest my make sure i wake up before i used to sleep very well before go out go to schools go to clubs i used to party very well but now i do nt used to do that again i used to drive i i will put on car drive out wherever whenever wherever i m going sorry i ca nt hear you no nobody either its to go out i do nt used to leave her at home go out i go with i go out with her ill put her inside car go out nobody to stay with her in past few weeks of earning factors such as professional commitment financial constraints for health challenges influence how you fees based on this these special therapists are attention caregiver used to allow her to allow person to come but now there is no financial support again from anybody so i had to go i had to carry out to government hospital for caring yes there is no changes cause i do nt have any money i m not i m not financially buoyant now sorry i ca nt hear yes i ca nt hear you fair enough i m i m fair enough fair enough health my is nt my home my mothers health my health at least i m copying little i get tired stress is too much for me i get tired every now then i m because i m taking care of my mother because i m i m caregiver to my mother i ve not seen any support from anyone i work remotely just work for three hours remaining hours is for taking care of her no he s answer my mother i m doing it because of my mother ill just make sure that i have given her her drugs her food then ill start working it has reduced my wages like like weeks ago now when i was working she she was awake i had to stop work when i was what what i had to stop what i was doing then attended attend to her this has affected me in lot of ways what do i do ah i used to give her more than more than hours as key given do you sometimes feel concerned about what future holds for you in that room if so could you share more about it what kind of help support will bear for you economist question as caregiver do you sometimes feel concerned about future what future holds for you in that if so yes yes yes because i need partner i will still have ill i m going to give birth have my husband get married one day so i need assistant i need partner too yes no no no no no please repeat question i ca nt hear you yes yes i m here i m here i need to dedicate my time to her voting of attention to financial support i ca nt remember not really i ca nt remember anything now like moment i i went to go look for some jobs to do she needs my attention so i had to attend to her before going she can remember me i show her some old videos of ours some pictures lots more she she react amazingly she goes into her room when someone comes in as in she as she reacts amazingly sometimes not every time no no no she does nt no she remembers me no no no i do nt used to allow her to go outside alone two times in week no no not him stressful\",\n          \"ok my name is yeah my name is john smith i am years old i am child to you know person with dementia is my father ok i m only one who is major caregiver ok answering question one well for past few weeks yeah its about years to years he s why so weak yeah i m i m always with him he stays with me we stay together so before going to my job i ensure he s fine i provide every basic things he needs you know he slowed his his emails his phone calls voicemails he has sure everything are kept in check sure he s using his medication they are all set before i go to my job at my job i always calling i calling at least twice to check on him to make sure he s doing fine make sure he s not having any reaction side effects to medication make sure he s resting one is supposed to make sure he s doing little exercise that has been prepared for him you know when i m back also i take him we go for walk take stroll around we do little exercise sometimes we go to church together there sure he also eats well eat fruits eats necessary things those use medication those little exercise then also on days of his visit to hospital sure i take him there on time i m always saying while he s in doctor we are done you know come back home so its just like normal thing you do for your child so it i immediately i m responsible for most of things ok someone says that ok well for past few weeks i would say pressure is much more lesser than before then i had you know when we first started it was lot for me to taking balancing being caregiver also having full time job its really really tough its really tough then being at entry level someone with little no you know superiority i have buses which i m also under their command you know its really hard to have my wish in time like that so then also its its always very difficult coping with new development you know things your father can do before easily before you find it you say that he s having hard time doing them you always just have to be around ensuring that it does it right so its always very tough to take in its really hard to believe that this is happening so for for past few weeks ice after that i m finding it little bit more easier because i ve let it become part of me i ve let it become something i do you know not because i want to receive award for some you know some people work because they just want to get pay some people do some things because they just want to you know receive profits from it but when you do something because of all of you have for person you do nt count it as something that even if its not reciprocated well you do nt see it as anything so i ve learned to teach myself to do it because i love my father my parents i would i m willing to go extra mile to make sure they re ok they re fine because they ve also sacrificed lot for me so for past few weeks i have made it my habits you know something i do without being for something i do without seeing it that s hard job though there s lot of challenge definitely lot of challenge tell him something he forgets it easily has few reactions some things you did yesterday you can remember some things you know lot of things lot of challenges but i ve learned to just calm down you know sometimes when its overwhelming i just take walk just listen to music just do something to calm me myself down because i can not be transferring aggression to him i can not show any sign of no anger any other things because it would really really affect his own wellbeing so i rather would rather take walk on his throat rather just turn my earbuds on listen to loud music just do something to just chill off before i can actually think on what next to do so i would say i m really coping nicely i m finding strategies to make it much more easier for me so that s how that is ok well relationship with friends family colleagues definitely there is shift i spend more time at home apart from my job apart from my job you know most times then i would love to socialize you know visit friends go to watch game go to at club go to lottery houses you know i spent my most of my free times there my weekends you know i m socializing i m hanging out i m doing lot of stuff sports now i have to spend there with my parents my dad because he needs care everything is getting better though but he needs care so that s affected my relationship with my friends well it makes me my wife have much more time together since i m spending more time at home with my father she s always around too so but with my friends that s really severed relationship we do lot of call video calls you know voice calls to kind of compensate for may not being able to show up there sometimes that some occasions will clash with days he has to go to hospital i just have to cancel occasion you know so its really done little to that my friends my colleagues you know my colleague maybe having birthday celebration at his home he s having occasion its classes with sometime by time i have to just be with my dad so most of them do actually understand they understand my situation they do nt get annoyed but definitely i would say it has really affected it has made me more introvert no staying indoors just loving things i can do indoors you know i only go out when i have to apart from my job sometimes i take my dad also sees to see game because he loves basketball so we go to watch some basketball sometimes makes him more happy makes him lively you know you see him celebrate him when he sees says he hook he goes cold some other things makes him more lively you know it adds makes health better some other things so that s pretty much how when i go out then relationship with my friends colleagues it has done little damage to it definitely definitely it is it is i it has it is about where its stopping me from going out its making me spend more time at home spend more time with my dad just ensuring that things are going as it should so but i do nt see that as you know when you people say barrier you know its something very negative something terrible something you do nt want to but it is what it is now i m not seeing it as barrier i m just saying that is that how can i describe it as alternative you know i m learning new way of life instead of being that you know extroverts talk so much going out partying having so much fun spending money wasting money wasting time doing some other things i now taking all those energies transfer it into something useful apart from while i m even caregiving i have some remote things i do i trade crypto i do some other things so i want to say its barrier anymore it has taught me how to actually invest in myself do things while i m at home so that also helped me in way ok well in my decision making process i think no real change no real change no real change any decision i need to make you know in regards to him sometimes he actually is able to make few decisions sometimes you know explaining some things to him he does nt understand we write it down let him greet we play it let him listen to it very slowly then if he understands he can make some decisions he makes about of decisions i make about so in regards to him i do nt think there is any change in my decision making process then its more than fine i think twice before i make any decisions i compare my alternatives i consider lot of choices before i can actually make decision but as regards myself well some decisions i make as regards my own life i shared this with my wife there s no real need of sharing with my dad because even if i shared with him before tomorrow he forgets something like that so my decisions as regards myself my family i do nt really share them with him because he do nt really are remembers most of those things few ones that actually you know like maybe ah ohh its your granddaughter birthday its your grandsons birthday something like that ohh its your its your wifes birthday its my birthday you know things like that that they re just for moment so we share those with him but you know real issues as regarding my decision making process i do nt share that with him there is no change you know when you say change in decision making process maybe because i m frustrated i make certain decisions because i m angry i make certain decisions i ve taught myself so much to be able to control all those calm myself down take it through listen to good music do something that just you know its little stressful now then when i m come when i m settled i can now think my way out of making very good decision because when you make decisions when you are annoyed most times it is end of time there are no good decisions because at that point i wo nt say you ve lost your mind but you are totally out of yourself such situation might be really really terrible have nasty consequences so i ve taught myself how to control them yeah that that is definitely true that s definitely true caregiving yes definitely it does affect it affects those decisions you know i before i go for any vacation of stuff i have to plan it very well it sure it does nt clash with you stuffs especially critical visits to hospitals so i make sure any vacation something does nt tamper with that well about location i have home here so i do nt see any circumstance of me you know moving out of this area for at least for next years so i love this place i settled in i think i m doing fine so but if there would be maybe case maybe any circumstance that would actually need relocation movement i think there even would definitely be barrier because we have to actually transfer hospitals then get stable around place where we are feed them with all previous information they need to know then continue doing it there because it definitely is factor i would consider before i make such kinds of huge decisions you know decisions that would really affect him like me going on vacation locating going for holidays somewhere something it is major function that i have to consider ok now commitment page yeah definitely professional commitment yes eversource definitely they have affected some things with us ok yeah self keep practicing yeah manage daily stress describe yourself here properties past weeks might stress of caregiving share strategies ok well selfcare practices like i said sometimes it gets very frustrating you know sometimes some things you tell him you forget its really annoying because sometimes its annoying definitely any normal person will get annoyed with some things like i said in previous recordings i have taught myself to manage these stresses it was nt days job two years job three years job its been over years now so i go for walk when i m having when i m feeling stress you know having gone to my full time job makes lot of difficulties stuffs problems every other thing i m coming back then i just want peace then i m still having lot of things to deal with you know frustration sets in terrible mood swings anger every other thing so i learned to take walk you know once its not that its in critical situation where i need to be there i will just take walk i just go to my music room put on my earbuds listen to music play piano do something that would ease my stress i just even go to sitting room just watch netflix just laugh laugh out sometimes then is stress away so some of strategies have actually been employing sure i go away from that you know i i go away from where he is just try to ease with stress then then sometimes then sometimes i just you know i just try to cope with it i makes decisions not to get annoyed you know some things are supposed to make you annoyed then to see why am i why am i why am i even getting annoyed for no reason listen is nt something much that should get me annoyed then i just flush out thought of being annoyed then take it as something normal so i think those are some of major strategies i have employed as regards coping with daily stresses every other stuff how frequently ill say ill say majorly five days week five days i got my job definitely very stressful well i would say is about him keeping to his routine he knows what he should be doing at this time he knows what he should be doing at that time then you ask him have you done this ohh i ve done it then you find out he s not done it ok he has call he has check up call from hospital while i m at my job he s not he s not picking them up he s not answering he say oh have you done this say ohh i do nt even know that i should have done that then you prepare you want to eat this food then you make it then you bring it he does nt want to eat it anymore he wants to eat something else you know lot of those things come up those are just few of examples its very stressful very annoying that s fifth one right yeah yeah factors such as professional commitment financial constraints yes our professional commitment definitely you know there was time i should you know have i my company was planning to actually sponsor me on trip to i think to united kingdom you know for seminar some other fellowship then for some other knowledge professional stuffs it was meant to be two weeks then i found way to get someone to stay with him every other thing it just fell apart i was nt able to go it was really painful at that moment at that moment i you know just had to back out of opportunity that i had been waiting all my life for then it was frustrating terrible well yeah it is what it is i have gotten something close that now so it does nt pin me so much when i think of it so lot of professional commitments you know sometimes i am supposed to do over some over time just to get some extra cash then i just ca nt i just have to be dashing out of office money time because i have someone i m caregiving you know its really really frustrating then you get home you meet some other stress some other things frustrating so i would say professional commitment care given standards barrier between lot of professional commitments as far as i m concerned then financial constraints health challenges well financial constraints for me at this moment well i thank god i think i m i m i m above moderate in very good salary my father also you know he s worked some things down for himself so he has his health insurance some other things that basically covered by job things he has done while he was still active so i do nt really have support care about financial stuff it is well available so i wo nt say financial constraints is really any problem then health changes well sometimes i also fall sick then sick person still caring for sick person so i try my as best as much as i as i can not to fall sick but when i do i well my wife actually takes takes responsibility of doing what i ve been doing so i think that s basically it i get distracted get lot of distraction lot lots of distraction you know sometimes he just makes some emergency call then you pick up you be like what s up says i just want to hear your voice you know that would be really annoying like you call me five times just want to hear my voice for what then i m just you know i see your call i m panicking now maybe something is wrong i just have to pick it up you know sometimes you see your call you know my brain say oh i m busy you just shoot them text i m busy ill call you later then that s all when you are done with job you call them but you see call you know it you know is someone ok given for so you just have to pick it up then you say ohh i just want to hear your voice why just want to do this then you be like do nt call me like this when i see your call i have to pick up because of this that do nt just call because when i hear my voice i m busy at my job some other things then he does nt hear he keeps calling so i get distracted lot so but its part of job of caregiving definitely well yes definitely there are some positions i want us to be promoted to but its going to definitely hit hit into time of my care given so i ve declined few of those offers then i hope it gets very very much more better soon then i can have less hours care given then maybe take some professional you know promotions no i sleep well i sleep well eat good he sleeps very he sleeps very early he wakes up late so i hardly have any issues at night i sleep well for me for him no no no no none of those ok do you sometimes feel concerned about what future holds for you in room yeah definitely i definitely think about that i definitely think about that i ve table that you know in family meetings some other stuff so you know no one is willing to take responsibility everyones busy everyone is doing this that it just feels like i just have to keep doing this forever then i think that well i ve actually declined lot of professional things i should have you know gotten promoted getting costing me more money getting me you know some other things then this cake even is staying as barrier some other things you know just thinking about some other things so i definitely have thoughts most of time what future holds for me in this role because if it continues like this for long time you know i would have to decline lot of offers along line i might still be in same position for years so i consider that then i m hoping very soon that one actually have enough finances we can actually transfer him to stable you know professional home where we have professional caregivers stuff like that but utmost prayer is that his conditions improve then we actually have less hours of caregiving then we are still caregivers that day but we have less hours because he can not do many things by himself well doctors are promised that that is possibility in nearest future we are also hoping that god if that is possible but if that does nt work out then at some point i wo nt be considering i would be considering professional caregiving homes so i guess that s it about that well truth is if i have someone someone else if we can run something like shift when i m active for these two days week then he s active for another two days match for another two days i m asking for hours day then he takes other hours you know something like that it would ease me of lot of stress lot of burdens then if possibly if we have enough finances we can just move him to professional place you know those ones they do nt see it as task they ve been trained for that then they do it to any living so that s their job they do nt have something else to stop in them so i think those might be two great options ok yeah definitely definitely i think about that by percent of time first of all its financial basis then also we ve had lot of stories about professional caregivers you know neglect terrible happenings that we ve had that does nt want he he he kicks he kicks against it he does nt want it we ve actually brought up in some meetings where family is willing to donate then get that done but he himself does nt want that he says if we try that he gets escaped from there he s gon na run off do some of that stuffs you know its really hard he does nt want it then we also we are concerned about risk so that s why were not really implemented he forgets lot very frequently ohh me no he does nt forget me he does nt forget me he knows me he knows me mostly forget some other family members but not not me not me does nt remember them yeah definitely like oh what are you what are you looking for you know sometimes like oh oh john i have stranger in this house its trying to come to front door doing this that you know i ve had calls like that when my wife you know my wife was back at her job then he called me up ohh john i have this woman lady at my door i do nt know what she s looking for can you call cops can you do this i m like its my wife for gods sake so you have issues like that so but he s not aggressive towards them he just wants to know who is who what is what i m sure he s safe i would say progressive out to neutral yeah so i do nt read it read it well i feel i might share my experiences then i was thinking maybe there are some resources that can actually help me caregiving journey maybe something like that would also be shared during meeting so those are things i m looking for\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the CSV files\n",
        "zbi_df = pd.read_csv('ZBI_preprocessed.csv')\n",
        "narrative_df = pd.read_csv('preprocessed_narrative.csv')\n",
        "\n",
        "narrative_df_last_three = narrative_df.iloc[:, -3:]\n",
        "merged_df = pd.concat([zbi_df, narrative_df_last_three], axis=1)\n",
        "merged_df.to_csv('Narrative_Plus_ZBI.csv', index=False)\n",
        "\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_df.iloc[:, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr03WQ6zNi31",
        "outputId": "a01394fd-d6a2-4e3e-93b6-660a124372a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      1\n",
            "1      2\n",
            "2      3\n",
            "3      4\n",
            "4      5\n",
            "      ..\n",
            "60    64\n",
            "61    65\n",
            "62    66\n",
            "63    67\n",
            "64    68\n",
            "Name: Participant ID, Length: 65, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "H6sZXAEYBDQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fishers"
      ],
      "metadata": {
        "id": "4uElRC8NKPXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from rpy2.robjects import pandas2ri\n",
        "# import rpy2.robjects as robjects\n",
        "# pandas2ri.activate()\n",
        "\n",
        "\n",
        "# def feature_selection(df, target_col, exclude_cols=None):\n",
        "#     \"\"\"\n",
        "#     Perform feature selection using Fisher/Freeman-Halton exact tests.\n",
        "#     Returns: list of selected features that have a p-value < 0.1 (most significant first)\n",
        "#     \"\"\"\n",
        "#     def calculate_p_value(feature):\n",
        "#         \"\"\"Helper function for p-value calculation\"\"\"\n",
        "#         try:\n",
        "#             # Create a contingency table for the feature and target\n",
        "#             contingency = pd.crosstab(df[feature], df[target_col])\n",
        "#             # Filter out rows with all zeros\n",
        "#             contingency = contingency.loc[(contingency != 0).any(axis=1)]\n",
        "#             if contingency.size == 0 or contingency.shape[1] < 2:\n",
        "#                 return None\n",
        "\n",
        "#             # Convert the pandas DataFrame to an R object (assumes rpy2 is configured)\n",
        "#             r_contingency = pandas2ri.py2rpy(contingency)\n",
        "#             num_levels = contingency.shape[0]\n",
        "\n",
        "#             # Use different R code depending on the number of levels\n",
        "#             r_code = \"\"\"\n",
        "#             function(mat) {\n",
        "#               test <- fisher.test(mat, workspace=1e8)\n",
        "#               return(test$p.value)\n",
        "#             }\n",
        "#             \"\"\" if num_levels > 2 else \"\"\"\n",
        "#             function(mat) {\n",
        "#               test <- fisher.test(mat, simulate.p.value=FALSE)\n",
        "#               return(test$p.value)\n",
        "#             }\n",
        "#             \"\"\"\n",
        "\n",
        "#             # Calculate and return the p-value from R\n",
        "#             return float(robjects.r(r_code)(r_contingency)[0])\n",
        "#         except Exception as e:\n",
        "#             print(f\"Skipped {feature}: {str(e)}\")\n",
        "#             return None\n",
        "\n",
        "#     # Exclude target and any additional columns\n",
        "#     exclude = [target_col] + (exclude_cols if exclude_cols else [])\n",
        "#     features = [col for col in df.columns if col not in exclude]\n",
        "\n",
        "#     # Compute p-values for each feature\n",
        "#     p_values = {}\n",
        "#     for feature in features:\n",
        "#         pval = calculate_p_value(feature)\n",
        "#         if pval is not None:\n",
        "#             p_values[feature] = pval\n",
        "\n",
        "#     # Return features with p-value < 0.1, sorted by ascending p-value\n",
        "#     selected_features = sorted([feature for feature, p in p_values.items() if p < 0.1],\n",
        "#                                key=lambda x: p_values[x])\n",
        "#     return selected_features"
      ],
      "metadata": {
        "id": "qFSwP2FIrb_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-sqaure"
      ],
      "metadata": {
        "id": "CA5-QczzKTCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(data, target_column, drop_columns):\n",
        "    # Create a copy of the data to avoid modifying the original\n",
        "    df = data.copy()\n",
        "\n",
        "    # Encode categorical variables using LabelEncoder\n",
        "    label_encoders = {}\n",
        "    for column in df.select_dtypes(include=['object']).columns:\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column].astype(str))\n",
        "        label_encoders[column] = le\n",
        "\n",
        "    # Handle missing values by filling them with the mode of each column\n",
        "    df.fillna(df.mode().iloc[0], inplace=True)\n",
        "\n",
        "    # Separate features and target variable\n",
        "    X = df.drop(columns=drop_columns + [target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Perform Chi-square test\n",
        "    chi2_scores, p_values = chi2(X, y)\n",
        "\n",
        "    # Create results DataFrame\n",
        "    chi2_results = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Chi2 Score': chi2_scores,\n",
        "        'P-Value': p_values\n",
        "    })\n",
        "\n",
        "    # Sort by p-value and filter significant features\n",
        "    significant_features = chi2_results[chi2_results['P-Value'] < 0.1]\\\n",
        "                          .sort_values(by='P-Value', ascending=True)\n",
        "\n",
        "    # Return all significant features\n",
        "    return significant_features['Feature'].tolist(), chi2_results"
      ],
      "metadata": {
        "id": "xNZsrV6XZebc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Narrative+PHQ**"
      ],
      "metadata": {
        "id": "_GQEqaPPPA9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "UFw0P967K7QD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+PHQ"
      ],
      "metadata": {
        "id": "1mGorHTWLBPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eshGCjAEHul3",
        "outputId": "908ab46b-044a-4195-bb21-ced1369cf16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.74\n",
            "LOOCV Precision: 0.68\n",
            "LOOCV Recall: 0.81\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Define custom labels\n",
        "labels = ['Not Depressed', 'Depressed']\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "\n",
        "plt.yticks(rotation=90, ha='center', va='center')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"Depressed (0): {cm[0, 0]} | Not Depressed (1): {cm[0, 1]}\")\n",
        "print(f\"Not Depressed (0): {cm[1, 0]} | Depressed (1): {cm[1, 1]}\")\n",
        "\n",
        "# Save the confusion matrix as an EPS file\n",
        "plt.savefig(\"confusion_matrix.eps\", format=\"eps\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "bIGisSurTVvv",
        "outputId": "2ba62bf9-407e-4b03-c7f8-a610755fc6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "Depressed (0): 29 | Not Depressed (1): 10\n",
            "Not Depressed (0): 5 | Depressed (1): 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+PHQ"
      ],
      "metadata": {
        "id": "XBs0JwoyLIzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b54ea4-8189-40cc-ef45-35ebefa29f92",
        "id": "Ev27aoRJcy1p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.56\n",
            "LOOCV Precision: 0.54\n",
            "LOOCV Recall: 0.58\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+PHQ"
      ],
      "metadata": {
        "id": "mBqAz9tULgAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c03e7207-da78-468c-a626-2a3e36088f8f",
        "id": "1L839tnMeD5Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.64\n",
            "LOOCV Precision: 0.63\n",
            "LOOCV Recall: 0.65\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LR"
      ],
      "metadata": {
        "id": "ZqeSubl0L7zM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+PHQ"
      ],
      "metadata": {
        "id": "RBE4ijgaL_0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f180f2c-4a74-415e-df73-a58fc9eb311b",
        "id": "BsUyjOyph28v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.70\n",
            "LOOCV Precision: 0.68\n",
            "LOOCV Recall: 0.73\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rO7x9tCOMp9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+PHQ"
      ],
      "metadata": {
        "id": "64GpAkbgim7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df0560f-be0a-4d10-fbfd-4867c3e16820",
        "id": "NwHabtDvim7D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.56\n",
            "LOOCV Precision: 0.54\n",
            "LOOCV Recall: 0.58\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+PHQ"
      ],
      "metadata": {
        "id": "81po_PRBim7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c89ddc-6471-4736-cf68-1ecee6ddd6de",
        "id": "yh94Wg_lim7D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.65\n",
            "LOOCV Precision: 0.65\n",
            "LOOCV Recall: 0.65\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN"
      ],
      "metadata": {
        "id": "xFx2S0TkUAEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+PHQ"
      ],
      "metadata": {
        "id": "gLEvejsmUAEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1b356a-80f1-4b73-9ae0-cd6fbe062011",
        "id": "diMzbRglkPhb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.46\n",
            "LOOCV Precision: 0.46\n",
            "LOOCV Recall: 0.46\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+PHQ"
      ],
      "metadata": {
        "id": "7HsBYA0okPhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c892267f-8d0e-4dc0-e991-7c78f20bf278",
        "id": "JWQSsL-OkPhc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.53\n",
            "LOOCV Precision: 0.48\n",
            "LOOCV Recall: 0.58\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+PHQ"
      ],
      "metadata": {
        "id": "PcfsEENdkPhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a938d79b-d1bc-4851-e0f3-3888ecd4a1fb",
        "id": "r2lWFdMSkPhc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.40\n",
            "LOOCV Precision: 0.42\n",
            "LOOCV Recall: 0.38\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "BnUAVTmTCOkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+PHQ"
      ],
      "metadata": {
        "id": "ThcPMf5qCOkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9626cba-1887-4158-cbc2-12750d4f4445",
        "id": "Cic9bnFQCOkj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.12\n",
            "LOOCV Precision: 0.33\n",
            "LOOCV Recall: 0.08\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+PHQ"
      ],
      "metadata": {
        "id": "DipVADn7COkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ADJ']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff95dc7-8b4a-4174-ade3-1af9a48ac7bf",
        "id": "1Jy1QdxiCOkk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.28\n",
            "LOOCV Precision: 0.50\n",
            "LOOCV Recall: 0.19\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+PHQ"
      ],
      "metadata": {
        "id": "v1F1CJ6ECOkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_PHQ.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'PHQ_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'PHQ_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['UNI']\n",
        "\n",
        "# Extract the 'PHQ_score' column as the label\n",
        "labels = data['PHQ_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['PHQ_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='PHQ_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e0fc83-faf9-4cc9-e0b9-ec05d37f6446",
        "id": "hRSTKQwKCOkk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.24\n",
            "LOOCV Precision: 0.57\n",
            "LOOCV Recall: 0.15\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 3: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 5: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 6: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 8: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 9: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 12: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 13: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 14: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 19: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 20: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 22: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 23: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 26: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Race']\n",
            "Iteration 28: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 33: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 34: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 37: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Ethnicity', 'Race']\n",
            "Iteration 38: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 39: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Relationship to Loved One', 'Race']\n",
            "Iteration 44: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 45: ['Location', 'Years Caring', 'Income', 'Age', 'Ethnicity', 'Education']\n",
            "Iteration 46: ['Location', 'Years Caring', 'Race', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 47: ['Location', 'Years Caring', 'Age', 'Education', 'Income', 'Ethnicity', 'Race']\n",
            "Iteration 48: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity', 'Race']\n",
            "Iteration 49: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 50: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Years Caring', 'Income', 'Education', 'Age', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 53: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity', 'Relationship to Loved One', 'Race']\n",
            "Iteration 54: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Race']\n",
            "Iteration 55: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 56: ['Location', 'Years Caring', 'Age', 'Income', 'Education', 'Ethnicity', 'Race']\n",
            "Iteration 57: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Years Caring', 'Income', 'Race', 'Ethnicity', 'Age', 'Education']\n",
            "Iteration 60: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Years Caring', 'Income', 'Race', 'Age', 'Education', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Years Caring', 'Income', 'Age', 'Education', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Years Caring: 65\n",
            "Income: 65\n",
            "Age: 65\n",
            "Education: 65\n",
            "Ethnicity: 60\n",
            "Race: 26\n",
            "Relationship to Loved One: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Narrative+ZBI**"
      ],
      "metadata": {
        "id": "WPeirYXlZlFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "haYBiz1RaAB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+ZBI"
      ],
      "metadata": {
        "id": "oiX0hOIgpuBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1188c67-5a39-4c49-f525-b2805257e90e",
        "id": "qg1hBjHfpuBs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.73\n",
            "LOOCV Precision: 0.72\n",
            "LOOCV Recall: 0.74\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+ZBI"
      ],
      "metadata": {
        "id": "IrWL7TtJpuBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc486bb2-c105-42ab-b52a-55d1265e62fc",
        "id": "RolYOyClpuBs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.71\n",
            "LOOCV Precision: 0.70\n",
            "LOOCV Recall: 0.72\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+ZBI"
      ],
      "metadata": {
        "id": "B0fno2QCmXEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    svm_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = svm_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef2f263-3908-4c34-ed03-ffaba037056b",
        "id": "5yFTlGAzmXEx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.67\n",
            "LOOCV Precision: 0.69\n",
            "LOOCV Recall: 0.64\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LR"
      ],
      "metadata": {
        "id": "10hokdfnmXEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+ZBI"
      ],
      "metadata": {
        "id": "fuS6oFVbmXEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6fac56-5f42-4e9a-d5db-1fe01f477a75",
        "id": "YjjxSQXsmXEy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.73\n",
            "LOOCV Precision: 0.72\n",
            "LOOCV Recall: 0.74\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+ZBI"
      ],
      "metadata": {
        "id": "dfyXqf3SmXEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e6c781-c2d2-47b4-f818-553a2527d084",
        "id": "nHREBu0smXEy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.75\n",
            "LOOCV Precision: 0.73\n",
            "LOOCV Recall: 0.77\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+ZBI"
      ],
      "metadata": {
        "id": "hNiO9OBsmXEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the logistic model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    logistic_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = logistic_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e74590-2606-45bf-bf25-5f737692382c",
        "id": "3vneg24UmXEy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.71\n",
            "LOOCV Precision: 0.73\n",
            "LOOCV Recall: 0.69\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN"
      ],
      "metadata": {
        "id": "66cOo6c7mXEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+ZBI"
      ],
      "metadata": {
        "id": "C2oEpRi2mXEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ACD' column into BoW unigram features\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6009c50-240a-46f2-ea51-059f248ee965",
        "id": "LLOIbkhkmXEz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.69\n",
            "LOOCV Precision: 0.72\n",
            "LOOCV Recall: 0.67\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+ZBI"
      ],
      "metadata": {
        "id": "gcrc19l3mXEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "adj_column = data['ADJ']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'ADJ' column into BoW unigram features\n",
        "adj_bow_features = vectorizer.fit_transform(adj_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-ACD features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with ADJ BoW features\n",
        "    X_train_combined = hstack([X_train_selected, adj_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, adj_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4427ef-1c1c-4925-d746-f5a89b5987aa",
        "id": "gbLM4QS9mXEz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.75\n",
            "LOOCV Precision: 0.78\n",
            "LOOCV Recall: 0.72\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+ZBI"
      ],
      "metadata": {
        "id": "R1RuZVCAmXEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "uni_column = data['UNI']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the 'UNI' column into BoW unigram features\n",
        "uni_bow_features = vectorizer.fit_transform(uni_column)\n",
        "\n",
        "#!!!!!!!!!!\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "\n",
        "# Get feature names for non-UNI features\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Initialize Leave-One-Subject-Out Cross-Validation (LOSO-CV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Prepare labels as a numpy array\n",
        "labels_array = labels.values\n",
        "\n",
        "# Perform LOSO-CV\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Convert X_train (sparse) to a DataFrame using the original feature names\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    # Add the target column so that feature_selection can operate on it\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Get indices of selected features (from feature_names)\n",
        "    selected_indices = [feature_names.index(feature) for feature in selected_features]\n",
        "\n",
        "    # Select features for training and testing\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine selected features with UNI BoW features\n",
        "    X_train_combined = hstack([X_train_selected, uni_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, uni_bow_features[test_index]])\n",
        "\n",
        "    # Train the model\n",
        "    knn_model.fit(X_train_combined, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "    # Store the results\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Print all selected features\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count feature selection frequency\n",
        "all_features = [feature for sublist in all_selected_features for feature in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74d3a86-412d-4eff-c079-485c049d033a",
        "id": "pFkdQSH0mXEz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.63\n",
            "LOOCV Precision: 0.62\n",
            "LOOCV Recall: 0.64\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "MZoTzfzvxm2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ACD+ZBI"
      ],
      "metadata": {
        "id": "XfNrbAirxm2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ADJ', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ACD', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ACD', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ACD' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ACD']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32792386-9359-4eed-9fae-0e926c1c2b4f",
        "id": "W1pZWcc_xm2g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.75\n",
            "LOOCV Precision: 0.60\n",
            "LOOCV Recall: 0.97\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ADJ+ZBI"
      ],
      "metadata": {
        "id": "Pce-CKNsxm2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'UNI'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'ADJ', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'ADJ', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'ADJ' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['ADJ']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44dd878-4df5-4e95-bfd0-0dad90861ca4",
        "id": "3mfi88GGAnhF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.77\n",
            "LOOCV Precision: 0.65\n",
            "LOOCV Recall: 0.95\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###UNI+PHQ"
      ],
      "metadata": {
        "id": "T56Kksvmxm2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import chi2\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"Narrative_Plus_ZBI.csv\")\n",
        "data = data.drop(['ACD', 'ADJ'], axis=1)\n",
        "\n",
        "# Extract features (all columns except 'Participant ID', 'UNI', and 'ZBI_score')\n",
        "features = data.drop(columns=['Participant ID', 'UNI', 'ZBI_score'])\n",
        "\n",
        "# Extract the 'UNI' column for Bag of Words (BoW) transformation\n",
        "acd_column = data['UNI']\n",
        "\n",
        "# Extract the 'ZBI_score' column as the label\n",
        "labels = data['ZBI_score']\n",
        "\n",
        "# Initialize CountVectorizer for unigram features\n",
        "vectorizer = CountVectorizer()\n",
        "acd_bow_features = vectorizer.fit_transform(acd_column)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "for column in features.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    features[column] = le.fit_transform(features[column].astype(str))\n",
        "\n",
        "# Convert features to sparse matrix\n",
        "features_sparse = csr_matrix(features.values)\n",
        "feature_names = features.columns.tolist()\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize LOSO-CV\n",
        "loo = LeaveOneOut()\n",
        "labels_array = labels.values\n",
        "\n",
        "# Track predictions and selected features\n",
        "predictions = []\n",
        "true_labels = []\n",
        "all_selected_features = []\n",
        "\n",
        "for train_index, test_index in loo.split(features_sparse):\n",
        "    X_train, X_test = features_sparse[train_index], features_sparse[test_index]\n",
        "    y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
        "\n",
        "    # Create DataFrame for feature selection\n",
        "    temp_train_df = pd.DataFrame(X_train.toarray(), columns=feature_names)\n",
        "    temp_train_df['ZBI_score'] = y_train\n",
        "\n",
        "    # Perform feature selection\n",
        "    selected_features, _ = feature_selection(temp_train_df, target_column='ZBI_score', drop_columns=[])\n",
        "    all_selected_features.append(selected_features)\n",
        "\n",
        "    # Map selected feature names to indices\n",
        "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
        "\n",
        "    # Select features\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    # Combine with ACD BoW features\n",
        "    X_train_combined = hstack([X_train_selected, acd_bow_features[train_index]])\n",
        "    X_test_combined = hstack([X_test_selected, acd_bow_features[test_index]])\n",
        "\n",
        "    # Train and predict\n",
        "    rf_model.fit(X_train_combined, y_train)\n",
        "    y_pred = rf_model.predict(X_test_combined)\n",
        "\n",
        "    predictions.append(y_pred[0])\n",
        "    true_labels.append(y_test[0])\n",
        "\n",
        "# Calculate metrics\n",
        "f1 = f1_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "precision = precision_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "recall = recall_score(true_labels, predictions, average='binary', zero_division=1)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nLOOCV F1 Score: {f1:.2f}\")\n",
        "print(f\"LOOCV Precision: {precision:.2f}\")\n",
        "print(f\"LOOCV Recall: {recall:.2f}\")\n",
        "\n",
        "# Display selected features per fold\n",
        "print(\"\\nAll selected features:\")\n",
        "for i, features in enumerate(all_selected_features):\n",
        "    print(f\"Iteration {i+1}: {features}\")\n",
        "\n",
        "# Count frequency of each feature\n",
        "all_features = [f for sublist in all_selected_features for f in sublist]\n",
        "feature_counts = Counter(all_features)\n",
        "\n",
        "print(\"\\nFeature selection frequency:\")\n",
        "for feature, count in feature_counts.most_common():\n",
        "    print(f\"{feature}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb25473a-c3b0-44df-84a6-4e23d6599aff",
        "id": "lF11Y8EFBPO-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOOCV F1 Score: 0.73\n",
            "LOOCV Precision: 0.60\n",
            "LOOCV Recall: 0.95\n",
            "\n",
            "All selected features:\n",
            "Iteration 1: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 2: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 3: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 4: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 5: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 6: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 7: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Age']\n",
            "Iteration 8: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 9: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 10: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 11: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 12: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 13: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 14: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 15: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 16: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 17: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 18: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 19: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 20: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 21: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 22: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 23: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 24: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 25: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 26: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 27: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 28: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 29: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 30: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 31: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 32: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 33: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 34: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 35: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 36: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 37: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 38: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 39: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 40: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 41: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 42: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 43: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 44: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 45: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 46: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 47: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 48: ['Race', 'Location', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 49: ['Race', 'Location', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 50: ['Location', 'Race', 'Income', 'Years Caring', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 51: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 52: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 53: ['Race', 'Location', 'Daily Caregiving Hours', 'Income', 'Years Caring', 'Ethnicity', 'Relationship to Loved One']\n",
            "Iteration 54: ['Location', 'Race', 'Income', 'Daily Caregiving Hours', 'Years Caring', 'Ethnicity']\n",
            "Iteration 55: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 56: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "Iteration 57: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 58: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 59: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 60: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 61: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 62: ['Location', 'Race', 'Years Caring', 'Income', 'Daily Caregiving Hours', 'Ethnicity']\n",
            "Iteration 63: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 64: ['Location', 'Race', 'Daily Caregiving Hours', 'Years Caring', 'Income', 'Ethnicity']\n",
            "Iteration 65: ['Location', 'Race', 'Years Caring', 'Daily Caregiving Hours', 'Income', 'Ethnicity']\n",
            "\n",
            "Feature selection frequency:\n",
            "Location: 65\n",
            "Race: 65\n",
            "Income: 65\n",
            "Daily Caregiving Hours: 65\n",
            "Years Caring: 65\n",
            "Ethnicity: 65\n",
            "Relationship to Loved One: 6\n",
            "Age: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hToKGY7sa_y5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}